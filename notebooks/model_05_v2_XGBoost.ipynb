{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "historic-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donn√©es brutes\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brilliant-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# On garde uniquement les lignes du train qui ont un score `sii`\n",
    "train = train.dropna(subset=[\"sii\"]).copy()\n",
    "train[\"sii\"] = train[\"sii\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes num√©riques\n",
    "num_cols = [\n",
    "    \"Basic_Demos-Age\",\n",
    "    \"Physical-BMI\",\n",
    "    \"PreInt_EduHx-computerinternet_hoursday\",\n",
    "    \"SDS-SDS_Total_T\"\n",
    "]\n",
    "\n",
    "# Colonnes cat√©gorielles simples\n",
    "cat_cols = [\n",
    "    \"Basic_Demos-Sex\",                 # 0 = Gar√ßon, 1 = Fille\n",
    "    \"Basic_Demos-Enroll_Season\",       # Saison d'inscription\n",
    "    \"Physical-Season\"                  # Saison des mesures physiques\n",
    "]\n",
    "\n",
    "# S√©lection des colonnes + la cible\n",
    "features = num_cols + cat_cols\n",
    "target = \"sii\"\n",
    "\n",
    "# ‚öôÔ∏è Cr√©ation des X, y\n",
    "X = train[features].copy()\n",
    "y = train[target]\n",
    "X_test = test[features].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "framed-ratio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç NaN dans X :\n",
      " Basic_Demos-Age                             0\n",
      "Physical-BMI                              209\n",
      "PreInt_EduHx-computerinternet_hoursday     82\n",
      "SDS-SDS_Total_T                           211\n",
      "Basic_Demos-Sex                             0\n",
      "Basic_Demos-Enroll_Season                   0\n",
      "Physical-Season                           141\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç NaN dans X :\\n\", X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "timely-tutorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " V√©rif NaN apr√®s imputation :\n",
      "Basic_Demos-Age                           0\n",
      "Physical-BMI                              0\n",
      "PreInt_EduHx-computerinternet_hoursday    0\n",
      "SDS-SDS_Total_T                           0\n",
      "Basic_Demos-Sex                           0\n",
      "Basic_Demos-Enroll_Season                 0\n",
      "Physical-Season                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# S√©paration num√©rique / cat√©goriel\n",
    "num_cols = [\"Basic_Demos-Age\", \"Physical-BMI\", \"PreInt_EduHx-computerinternet_hoursday\", \"SDS-SDS_Total_T\"]\n",
    "cat_cols = [\"Basic_Demos-Sex\", \"Basic_Demos-Enroll_Season\", \"Physical-Season\"]\n",
    "\n",
    "# Imputation num√©rique (m√©diane)\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "X[num_cols] = num_imputer.fit_transform(X[num_cols])\n",
    "X_test[num_cols] = num_imputer.transform(X_test[num_cols])\n",
    "\n",
    "# Imputation cat√©gorielle (mode)\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "X[cat_cols] = cat_imputer.fit_transform(X[cat_cols])\n",
    "X_test[cat_cols] = cat_imputer.transform(X_test[cat_cols])\n",
    "\n",
    "# V√©rification\n",
    "print(\" V√©rif NaN apr√®s imputation :\")\n",
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advance-globe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encodage termin√©.\n",
      "   Basic_Demos-Sex  Basic_Demos-Enroll_Season  Physical-Season\n",
      "0                0                          0                0\n",
      "1                0                          2                0\n",
      "2                1                          2                0\n",
      "3                0                          3                2\n",
      "5                1                          1                2\n"
     ]
    }
   ],
   "source": [
    "# On encode chaque colonne cat√©gorielle une par une\n",
    "encoders = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    X_test[col] = le.transform(X_test[col])  # attention : le test doit suivre l‚Äôordre du train\n",
    "    encoders[col] = le  # on les garde si besoin de d√©coder plus tard\n",
    "\n",
    "print(\"Encodage termin√©.\")\n",
    "print(X[cat_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tender-compression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:54:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Meilleurs param√®tres XGBoost: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7}\n",
      "[16:54:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost - QWK Score : 0.3355\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# üåü Mod√®le XGBoost de base\n",
    "xgb = XGBClassifier(random_state=42, n_jobs=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# üîç Grille d'hyperparam√®tres\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 200],\n",
    "    'subsample': [0.7, 1.0]\n",
    "}\n",
    "\n",
    "# ‚öñÔ∏è GridSearch avec scoring QWK\n",
    "grid = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc_ovr',  # approximation multiclasses\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entra√Ænement avec GridSearch\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Meilleurs param√®tres trouv√©s\n",
    "print(\"Meilleurs param√®tres XGBoost:\", grid.best_params_)\n",
    "\n",
    "# Mod√®le final avec les meilleurs param√®tres\n",
    "final_xgb = XGBClassifier(**grid.best_params_, random_state=42, n_jobs=1)\n",
    "final_xgb.fit(X_train, y_train)\n",
    "\n",
    "# üìà Pr√©dictions\n",
    "y_pred = final_xgb.predict(X_val)\n",
    "\n",
    "# üß™ √âvaluation\n",
    "qwk = cohen_kappa_score(y_val, y_pred, weights='quadratic')\n",
    "print(f\"XGBoost - QWK Score : {qwk:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-resolution",
   "metadata": {},
   "source": [
    "##  Conclusion ‚Äì Mod√®le XGBoost\n",
    "\n",
    "Dans cette √©tape, nous avons test√© le mod√®le **XGBoost** avec une recherche d'hyperparam√®tres (GridSearch) :\n",
    "\n",
    "- **Meilleurs param√®tres** trouv√©s :\n",
    "  - `learning_rate = 0.1`\n",
    "  - `max_depth = 3`\n",
    "  - `subsample = 0.7`\n",
    "  - `n_estimators = 100`\n",
    "- **QWK score** avec XGBoost : **0.3355**\n",
    "\n",
    "Bien que XGBoost soit un mod√®le performant, **LightGBM reste l√©g√®rement au-dessus avec un score QWK de 0.3499**. \n",
    "\n",
    "Conclusion : \n",
    "- **XGBoost est une bonne alternative**, mais pour ce cas pr√©cis, **LightGBM est l√©g√®rement plus performant** apr√®s optimisation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "harmful-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/model_XGBoost.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sauvegarder le mod√®le XGBoost\n",
    "joblib.dump(final_xgb, '../models/model_XGBoost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-yukon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-borough",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
